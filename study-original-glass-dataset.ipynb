{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt to do the experiments\n",
    "\n",
    "Attempt to do the experiments with the original Glass dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from milp import codify_network\n",
    "from teste import get_minimal_explanation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opening the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe  target\n",
       "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0       1\n",
       "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0       1\n",
       "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0       1\n",
       "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0       1\n",
       "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0       1\n",
       "..       ...    ...   ...   ...    ...   ...   ...   ...  ...     ...\n",
       "200  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0       7\n",
       "201  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0       7\n",
       "202  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0       7\n",
       "203  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0       7\n",
       "204  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0       7\n",
       "\n",
       "[205 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datasets/glass/glass.tsv', sep='\\t')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing the data\n",
    "\n",
    "<!-- The normalization will be simply to shrink all values to be from -1 to 1.\n",
    "The minimum value will be -1; the maximum, 1.\n",
    "To shrink I'll simply divide every value be the whole range of the feature. -->\n",
    "\n",
    "I'll bring the mean to 0 by translating the data by the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in data.columns[:-1]:\n",
    "    data[column_name] -= data[column_name].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.286537</td>\n",
       "      <td>1.744927</td>\n",
       "      <td>-0.348341</td>\n",
       "      <td>-0.846537</td>\n",
       "      <td>-0.458878</td>\n",
       "      <td>-0.189415</td>\n",
       "      <td>-0.182732</td>\n",
       "      <td>-0.059512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000795</td>\n",
       "      <td>0.536537</td>\n",
       "      <td>0.854927</td>\n",
       "      <td>-0.088341</td>\n",
       "      <td>0.103463</td>\n",
       "      <td>-0.038878</td>\n",
       "      <td>-1.109415</td>\n",
       "      <td>-0.182732</td>\n",
       "      <td>-0.059512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002225</td>\n",
       "      <td>0.176537</td>\n",
       "      <td>0.804927</td>\n",
       "      <td>0.091659</td>\n",
       "      <td>0.363463</td>\n",
       "      <td>-0.128878</td>\n",
       "      <td>-1.159415</td>\n",
       "      <td>-0.182732</td>\n",
       "      <td>-0.059512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000745</td>\n",
       "      <td>-0.143463</td>\n",
       "      <td>0.944927</td>\n",
       "      <td>-0.158341</td>\n",
       "      <td>-0.016537</td>\n",
       "      <td>0.051122</td>\n",
       "      <td>-0.719415</td>\n",
       "      <td>-0.182732</td>\n",
       "      <td>-0.059512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000985</td>\n",
       "      <td>-0.083463</td>\n",
       "      <td>0.874927</td>\n",
       "      <td>-0.208341</td>\n",
       "      <td>0.453463</td>\n",
       "      <td>0.031122</td>\n",
       "      <td>-0.869415</td>\n",
       "      <td>-0.182732</td>\n",
       "      <td>-0.059512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-0.002175</td>\n",
       "      <td>0.786537</td>\n",
       "      <td>-2.745073</td>\n",
       "      <td>1.431659</td>\n",
       "      <td>-0.016537</td>\n",
       "      <td>-0.438878</td>\n",
       "      <td>0.240585</td>\n",
       "      <td>0.877268</td>\n",
       "      <td>-0.059512</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>-0.001555</td>\n",
       "      <td>1.566537</td>\n",
       "      <td>-2.745073</td>\n",
       "      <td>0.541659</td>\n",
       "      <td>0.433463</td>\n",
       "      <td>-0.518878</td>\n",
       "      <td>-0.539415</td>\n",
       "      <td>1.407268</td>\n",
       "      <td>-0.059512</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.002245</td>\n",
       "      <td>1.006537</td>\n",
       "      <td>-2.745073</td>\n",
       "      <td>0.571659</td>\n",
       "      <td>0.793463</td>\n",
       "      <td>-0.518878</td>\n",
       "      <td>-0.499415</td>\n",
       "      <td>1.457268</td>\n",
       "      <td>-0.059512</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-0.001895</td>\n",
       "      <td>1.026537</td>\n",
       "      <td>-2.745073</td>\n",
       "      <td>0.491659</td>\n",
       "      <td>0.983463</td>\n",
       "      <td>-0.518878</td>\n",
       "      <td>-0.459415</td>\n",
       "      <td>1.387268</td>\n",
       "      <td>-0.059512</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>-0.001295</td>\n",
       "      <td>0.876537</td>\n",
       "      <td>-2.745073</td>\n",
       "      <td>0.631659</td>\n",
       "      <td>0.733463</td>\n",
       "      <td>-0.518878</td>\n",
       "      <td>-0.319415</td>\n",
       "      <td>1.487268</td>\n",
       "      <td>-0.059512</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           RI        Na        Mg        Al        Si         K        Ca  \\\n",
       "0    0.002605  0.286537  1.744927 -0.348341 -0.846537 -0.458878 -0.189415   \n",
       "1   -0.000795  0.536537  0.854927 -0.088341  0.103463 -0.038878 -1.109415   \n",
       "2   -0.002225  0.176537  0.804927  0.091659  0.363463 -0.128878 -1.159415   \n",
       "3   -0.000745 -0.143463  0.944927 -0.158341 -0.016537  0.051122 -0.719415   \n",
       "4   -0.000985 -0.083463  0.874927 -0.208341  0.453463  0.031122 -0.869415   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "200 -0.002175  0.786537 -2.745073  1.431659 -0.016537 -0.438878  0.240585   \n",
       "201 -0.001555  1.566537 -2.745073  0.541659  0.433463 -0.518878 -0.539415   \n",
       "202  0.002245  1.006537 -2.745073  0.571659  0.793463 -0.518878 -0.499415   \n",
       "203 -0.001895  1.026537 -2.745073  0.491659  0.983463 -0.518878 -0.459415   \n",
       "204 -0.001295  0.876537 -2.745073  0.631659  0.733463 -0.518878 -0.319415   \n",
       "\n",
       "           Ba        Fe  target  \n",
       "0   -0.182732 -0.059512       1  \n",
       "1   -0.182732 -0.059512       1  \n",
       "2   -0.182732 -0.059512       1  \n",
       "3   -0.182732 -0.059512       1  \n",
       "4   -0.182732 -0.059512       1  \n",
       "..        ...       ...     ...  \n",
       "200  0.877268 -0.059512       7  \n",
       "201  1.407268 -0.059512       7  \n",
       "202  1.457268 -0.059512       7  \n",
       "203  1.387268 -0.059512       7  \n",
       "204  1.487268 -0.059512       7  \n",
       "\n",
       "[205 rows x 10 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll try to shrink the ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in data.columns[:-1]:\n",
    "\tlength = data[column_name].max() - data[column_name].min()\n",
    "\tdata[column_name] /= length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is between -1 and 1, and the mean is 0.\n",
    "\n",
    "This normalization guarantees the algorithm will stretch each range more or less in the same time.\n",
    "\n",
    "\n",
    "## Part II\n",
    "\n",
    "#### Splitting the dataset\n",
    "\n",
    "I'll split the dataset for training and testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('target', axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III\n",
    "\n",
    "#### Generating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "num_neurons = 20\n",
    "num_hidden_layers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for axis 1 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/tiagovargas/Documents/explainable-anns/study-original-glass-dataset.ipynb Cell 18\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tiagovargas/Documents/explainable-anns/study-original-glass-dataset.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_train_ohe \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mto_categorical(y_train, num_classes)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tiagovargas/Documents/explainable-anns/study-original-glass-dataset.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_test_ohe \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_categorical(y_test, num_classes)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/np_utils.py:73\u001b[0m, in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     71\u001b[0m n \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     72\u001b[0m categorical \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n, num_classes), dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m---> 73\u001b[0m categorical[np\u001b[39m.\u001b[39;49marange(n), y] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     74\u001b[0m output_shape \u001b[39m=\u001b[39m input_shape \u001b[39m+\u001b[39m (num_classes,)\n\u001b[1;32m     75\u001b[0m categorical \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(categorical, output_shape)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 7 is out of bounds for axis 1 with size 5"
     ]
    }
   ],
   "source": [
    "y_train_ohe = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_ohe = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 - 2s - loss: 2.0341 - accuracy: 0.3660 - val_loss: 1.9807 - val_accuracy: 0.3462 - 2s/epoch - 55ms/step\n",
      "Epoch 2/100\n",
      "39/39 - 0s - loss: 1.8872 - accuracy: 0.3791 - val_loss: 1.7835 - val_accuracy: 0.3462 - 145ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "39/39 - 0s - loss: 1.6092 - accuracy: 0.3791 - val_loss: 1.4707 - val_accuracy: 0.3462 - 126ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "39/39 - 0s - loss: 1.3521 - accuracy: 0.4641 - val_loss: 1.2577 - val_accuracy: 0.4038 - 201ms/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "39/39 - 0s - loss: 1.1725 - accuracy: 0.5098 - val_loss: 1.1193 - val_accuracy: 0.4038 - 142ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "39/39 - 0s - loss: 1.0569 - accuracy: 0.5882 - val_loss: 1.0574 - val_accuracy: 0.4231 - 196ms/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "39/39 - 0s - loss: 1.0073 - accuracy: 0.5425 - val_loss: 1.0184 - val_accuracy: 0.4423 - 242ms/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "39/39 - 0s - loss: 0.9717 - accuracy: 0.5621 - val_loss: 1.0080 - val_accuracy: 0.4808 - 188ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "39/39 - 0s - loss: 0.9241 - accuracy: 0.6144 - val_loss: 1.0056 - val_accuracy: 0.4423 - 302ms/epoch - 8ms/step\n",
      "Epoch 10/100\n",
      "39/39 - 0s - loss: 0.8967 - accuracy: 0.6275 - val_loss: 0.9762 - val_accuracy: 0.4615 - 265ms/epoch - 7ms/step\n",
      "Epoch 11/100\n",
      "39/39 - 0s - loss: 0.8725 - accuracy: 0.6928 - val_loss: 0.9866 - val_accuracy: 0.4808 - 293ms/epoch - 8ms/step\n",
      "Epoch 12/100\n",
      "39/39 - 1s - loss: 0.8584 - accuracy: 0.6340 - val_loss: 0.9656 - val_accuracy: 0.4615 - 537ms/epoch - 14ms/step\n",
      "Epoch 13/100\n",
      "39/39 - 1s - loss: 0.8516 - accuracy: 0.6732 - val_loss: 0.9905 - val_accuracy: 0.4615 - 670ms/epoch - 17ms/step\n",
      "Epoch 14/100\n",
      "39/39 - 0s - loss: 0.8232 - accuracy: 0.6797 - val_loss: 0.9537 - val_accuracy: 0.5962 - 277ms/epoch - 7ms/step\n",
      "Epoch 15/100\n",
      "39/39 - 0s - loss: 0.8096 - accuracy: 0.6405 - val_loss: 0.9383 - val_accuracy: 0.6538 - 437ms/epoch - 11ms/step\n",
      "Epoch 16/100\n",
      "39/39 - 0s - loss: 0.7978 - accuracy: 0.6863 - val_loss: 0.9545 - val_accuracy: 0.6346 - 151ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "39/39 - 0s - loss: 0.7805 - accuracy: 0.6928 - val_loss: 0.9447 - val_accuracy: 0.5577 - 264ms/epoch - 7ms/step\n",
      "Epoch 18/100\n",
      "39/39 - 0s - loss: 0.7635 - accuracy: 0.6863 - val_loss: 0.9557 - val_accuracy: 0.5962 - 359ms/epoch - 9ms/step\n",
      "Epoch 19/100\n",
      "39/39 - 0s - loss: 0.7485 - accuracy: 0.6993 - val_loss: 0.9761 - val_accuracy: 0.5769 - 333ms/epoch - 9ms/step\n",
      "Epoch 20/100\n",
      "39/39 - 0s - loss: 0.7270 - accuracy: 0.7124 - val_loss: 0.9225 - val_accuracy: 0.6346 - 122ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "39/39 - 0s - loss: 0.7370 - accuracy: 0.7190 - val_loss: 0.9585 - val_accuracy: 0.5962 - 144ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "39/39 - 0s - loss: 0.7278 - accuracy: 0.7255 - val_loss: 0.9475 - val_accuracy: 0.5962 - 114ms/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "39/39 - 0s - loss: 0.7228 - accuracy: 0.7059 - val_loss: 0.9656 - val_accuracy: 0.6154 - 225ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "39/39 - 0s - loss: 0.6985 - accuracy: 0.7124 - val_loss: 0.9719 - val_accuracy: 0.5962 - 215ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "39/39 - 0s - loss: 0.6872 - accuracy: 0.7255 - val_loss: 1.0044 - val_accuracy: 0.5769 - 161ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "39/39 - 0s - loss: 0.6775 - accuracy: 0.7255 - val_loss: 0.9333 - val_accuracy: 0.6346 - 183ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "39/39 - 0s - loss: 0.6741 - accuracy: 0.7320 - val_loss: 0.9659 - val_accuracy: 0.6154 - 368ms/epoch - 9ms/step\n",
      "Epoch 28/100\n",
      "39/39 - 0s - loss: 0.6657 - accuracy: 0.7320 - val_loss: 0.9683 - val_accuracy: 0.6154 - 402ms/epoch - 10ms/step\n",
      "Epoch 29/100\n",
      "39/39 - 0s - loss: 0.6601 - accuracy: 0.6993 - val_loss: 0.9156 - val_accuracy: 0.6538 - 322ms/epoch - 8ms/step\n",
      "Epoch 30/100\n",
      "39/39 - 0s - loss: 0.6516 - accuracy: 0.7582 - val_loss: 0.9901 - val_accuracy: 0.6154 - 253ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "39/39 - 0s - loss: 0.6435 - accuracy: 0.7451 - val_loss: 0.9721 - val_accuracy: 0.6346 - 206ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "39/39 - 0s - loss: 0.6376 - accuracy: 0.7582 - val_loss: 0.9974 - val_accuracy: 0.6538 - 102ms/epoch - 3ms/step\n",
      "Epoch 33/100\n",
      "39/39 - 0s - loss: 0.6175 - accuracy: 0.7778 - val_loss: 1.0744 - val_accuracy: 0.5962 - 95ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "39/39 - 0s - loss: 0.6285 - accuracy: 0.7320 - val_loss: 0.9862 - val_accuracy: 0.6346 - 103ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "39/39 - 0s - loss: 0.6009 - accuracy: 0.7582 - val_loss: 0.9869 - val_accuracy: 0.6731 - 159ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "39/39 - 0s - loss: 0.5961 - accuracy: 0.7843 - val_loss: 1.0014 - val_accuracy: 0.6346 - 109ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "39/39 - 0s - loss: 0.6043 - accuracy: 0.7778 - val_loss: 1.0145 - val_accuracy: 0.6346 - 258ms/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "39/39 - 1s - loss: 0.5772 - accuracy: 0.7843 - val_loss: 0.9891 - val_accuracy: 0.6731 - 540ms/epoch - 14ms/step\n",
      "Epoch 39/100\n",
      "39/39 - 0s - loss: 0.5697 - accuracy: 0.7843 - val_loss: 0.9792 - val_accuracy: 0.6923 - 486ms/epoch - 12ms/step\n",
      "Tempo de Treinamento: 12.222784280776978\n",
      "Resultado Treinamento\n",
      "5/5 - 0s - loss: 0.5542 - accuracy: 0.8105 - 478ms/epoch - 96ms/step\n",
      "Resultado Teste\n",
      "2/2 - 0s - loss: 0.9792 - accuracy: 0.6923 - 95ms/epoch - 47ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9792033433914185, 0.692307710647583]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time \n",
    "\n",
    "keras_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=[x_train.shape[1]]),\n",
    "])\n",
    "\n",
    "for _ in range(num_hidden_layers):\n",
    "    keras_model.add(tf.keras.layers.Dense(num_neurons, activation='relu'))\n",
    "\n",
    "keras_model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "keras_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'], )\n",
    "\n",
    "model_path = f'datasets/dir_path/model_{num_hidden_layers}layers_glass.h5'\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "ck = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "start = time()\n",
    "keras_model.fit(x_train, y_train_ohe, batch_size=4, epochs=100, validation_data=(x_test, y_test_ohe), verbose=2, callbacks=[ck, es])\n",
    "print(f'Tempo de Treinamento: {time()-start}')\n",
    "\n",
    "keras_model = tf.keras.models.load_model(model_path)\n",
    "print('Resultado Treinamento')\n",
    "keras_model.evaluate(x_train, y_train_ohe, verbose=2)\n",
    "\n",
    "print('Resultado Teste')\n",
    "keras_model.evaluate(x_test, y_test_ohe, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mp_model, output_bounds) = codify_network(keras_model, data, 'fischetti', relax_constraints=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 138\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(138, slice(None, -1, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(138, slice(None, -1, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tiagovargas/Documents/explainable-anns/study-original-glass-dataset.ipynb Cell 22\u001b[0m in \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tiagovargas/Documents/explainable-anns/study-original-glass-dataset.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m138\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tiagovargas/Documents/explainable-anns/study-original-glass-dataset.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mi =\u001b[39m\u001b[39m'\u001b[39m, i)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tiagovargas/Documents/explainable-anns/study-original-glass-dataset.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m network_input \u001b[39m=\u001b[39m data[i, :\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tiagovargas/Documents/explainable-anns/study-original-glass-dataset.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m network_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(tf\u001b[39m.\u001b[39mconstant(network_input), [\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tiagovargas/Documents/explainable-anns/study-original-glass-dataset.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m network_output \u001b[39m=\u001b[39m keras_model\u001b[39m.\u001b[39mpredict(tf\u001b[39m.\u001b[39mconstant(network_input))[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3807\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3807\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[1;32m   3808\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:5963\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5959\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   5960\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5961\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5962\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5963\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (138, slice(None, -1, None))"
     ]
    }
   ],
   "source": [
    "# i = 134 is also a nice value to study\n",
    "i = 138\n",
    "print('i =', i)\n",
    "network_input = data[i, :-1]\n",
    "network_input = tf.reshape(tf.constant(network_input), [1, -1])\n",
    "network_output = keras_model.predict(tf.constant(network_input))[0]\n",
    "network_output = tf.argmax(network_output)\n",
    "\n",
    "predictions = keras_model.predict(tf.constant(network_input))[0, 0]\n",
    "\n",
    "print(f'Predictions: (ndarray[ndarray[{type(predictions)}]])', predictions)\n",
    "classification = network_output.numpy()\n",
    "print(f'Network output: ({type(classification)})', classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
