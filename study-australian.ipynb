{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study â€“ Australian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from milp import codify_network\n",
    "from teste import get_minimal_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For type annotations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'australian'\n",
    "\n",
    "training_data = pd.read_csv(f'datasets/{dataset_name}/train.csv')\n",
    "testing_data = pd.read_csv(f'datasets/{dataset_name}/test.csv')\n",
    "\n",
    "dataframe = pd.concat([training_data, testing_data])\n",
    "\n",
    "keras_model = tf.keras.models.load_model(f'datasets/{dataset_name}/model_4layers_{dataset_name}.h5')\n",
    "\n",
    "data = dataframe.to_numpy()\n",
    "n_classes = dataframe['target'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_model, output_bounds = codify_network(keras_model, dataframe, 'fischetti', relax_constraints=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing What the Model Predicted\n",
    "\n",
    "_Aka_ printing the network output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "print('i =', i)\n",
    "network_input = data[i, :-1]\n",
    "network_input = tf.reshape(tf.constant(network_input), [1, -1])\n",
    "network_output = keras_model.predict(tf.constant(network_input))[0]\n",
    "network_output = tf.argmax(network_output)\n",
    "\n",
    "predictions = keras_model.predict(tf.constant(network_input))[0, 0]\n",
    "\n",
    "print(f'Predictions: (ndarray[ndarray[{type(predictions)}]])', predictions)\n",
    "classification: np.int64 = network_output.numpy()\n",
    "print(f'Network output: ({type(classification)})', classification)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the Minimal Explanation\n",
    "\n",
    "Minimal eplanations only indicates which inputs are relevant to get to a conclusion.\n",
    "\n",
    "**Note:** The explanation happens _after_ the keras_model make its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_aux = mp_model.clone()\n",
    "\n",
    "minimal_explanation = get_minimal_explanation(mdl_aux, network_input, network_output, n_classes, 'fischetti', output_bounds)\n",
    "\n",
    "minimal_explanation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The keras_model predicted $C_1$ because:\n",
    ">\n",
    "> $x_0 = 2.967691214515491$,\n",
    ">\n",
    "> $x_3 = -1.408120229258977$,\n",
    ">\n",
    "> $x_5 = -0.790702170757714$, \n",
    ">\n",
    "> $x_6 = 4.24127975754059$, \n",
    ">\n",
    "> $x_7 = -0.3615292659832898$ and \n",
    ">\n",
    "> $x_8 = -0.6037614142464092$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to Improve the Explanation\n",
    "\n",
    "Given a minimal explanation, can we improve it?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constraints of type $x = c$ are equivalent to $x \\le c \\land x \\ge c$.\n",
    "\n",
    "Therefore, we need to substitute each $x = c$ constraint by the $x \\le c$ and $x \\ge c$ constraints.\n",
    "\n",
    "Then, we try stretching the interval by substituting $x \\le c$ by $x \\le c + \\Delta x$ and see if our prediction changes. If the prediction stays the same, then we substitue and try stretching it again. If the prediction changes, then this new interval isn't valid and we don't substitute. We found the upper bound of the interval, i.e. $x \\le c$.\n",
    "\n",
    "Then we try to stretch the interval to fin the lower bound. Analogously, We try substituting $c \\ge x$ by ????/\n",
    "\n",
    "\n",
    "We will end up with a pair of constraints the looks like $c - k_l \\cdot \\Delta{x} \\le x$ and $x \\le c + k_u \\cdot \\Delta{x}$, i.e. this pair represents $c - k_l \\cdot \\Delta{x} \\le x \\le c + k_u \\cdot \\Delta{x}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_model = mdl_aux\n",
    "testing_model = minimal_model.clone()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Sratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_constraints = testing_model.find_matching_linear_constraints('input')\n",
    "linear_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_constraints = testing_model.find_matching_linear_constraints('input')\n",
    "\n",
    "for constraint in linear_constraints:\n",
    "\ttesting_model.remove_constraint(constraint)\n",
    "\ttesting_model.add_constraint(constraint.lhs <= constraint.rhs.clone(), 'input LE')\n",
    "\ttesting_model.add_constraint(constraint.lhs >= constraint.rhs.clone(), 'input GE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_constraints = testing_model.find_matching_linear_constraints('input')\n",
    "linear_constraints"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing the bounds of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in testing_model.find_matching_vars('x'):\n",
    "\tprint(variable.lb, variable, variable.ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "\n",
    "variables = testing_model.find_matching_vars('x')\n",
    "\n",
    "for constraint in linear_constraints:\n",
    "\ttesting_model.solve()\n",
    "\tprint('Initial constraint:' + '\\t', constraint)\n",
    "\n",
    "\tvariable = constraint.lhs\n",
    "\twhile testing_model.solution is None:\n",
    "\t\tif constraint.sense == docplex.mp.constants.ComparisonType.LE:\n",
    "\t\t\tif constraint.rhs.constant <= variable.ub:\n",
    "\t\t\t\tconstraint.rhs += epsilon\n",
    "\t\t\telse:\n",
    "\t\t\t\tbreak\n",
    "\t\telif constraint.sense == docplex.mp.constants.ComparisonType.GE:\n",
    "\t\t\tif constraint.rhs.constant >= variable.lb:\n",
    "\t\t\t\tconstraint.rhs -= epsilon\n",
    "\t\t\telse:\n",
    "\t\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\traise Exception('Constraint sense was neither LE nor GE')\n",
    "\n",
    "\t\ttesting_model.solve()\n",
    "\n",
    "\t# Undo last operation\n",
    "\tif constraint.sense == docplex.mp.constants.ComparisonType.LE:\n",
    "\t\tconstraint.rhs -= epsilon\n",
    "\telif constraint.sense == docplex.mp.constants.ComparisonType.GE:\n",
    "\t\tconstraint.rhs += epsilon\n",
    "\n",
    "\tprint('Final constraint:' + '\\t', constraint)\n",
    "\tprint()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Rewrite pair of expression of type $x \\le c$ and $x \\ge c$ to $x = c$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_constraints = testing_model.find_matching_linear_constraints('input')\n",
    "linear_constraints"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `x_6` is actually equal to `4.24127975754059`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_inputs = len(dataframe.columns.drop('target'))\n",
    "for i in range(number_of_inputs):\n",
    "\tconstraints_of_x_i = filter(lambda x: x.lhs.name == f'x_{i}', linear_constraints)\n",
    "\tconstraints = [c for c in constraints_of_x_i]\n",
    "\n",
    "\tif len(constraints) == 2:\n",
    "\t\tif constraints[0].rhs.constant == constraints[1].rhs.constant:\n",
    "\t\t\ttesting_model.remove_constraints(constraints)\n",
    "\t\t\ttesting_model.add_constraint(constraints[0].lhs == constraints[0].rhs, 'input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_explanation = testing_model.find_matching_linear_constraints('input')\n",
    "improved_explanation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretty Printing the Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable_index(variable: docplex.mp.dvar.Var) -> int:\n",
    "\tindex = variable.name.split('_')[1]\n",
    "\treturn int(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_explanation(explanation: list[docplex.mp.constr.LinearConstraint]):\n",
    "\tfor e in explanation:\n",
    "\t\tvariable = e.lhs\n",
    "\t\tindex = get_variable_index(variable)\n",
    "\t\tfeature_name = dataframe.columns[index]\n",
    "\t\tprint(feature_name, e.sense.operator_symbol, e.rhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_explanation(improved_explanation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with Anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor import utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = utils.load_csv_dataset(\n",
    "\tdata=f'datasets/{dataset_name}/test.csv',\n",
    "\ttarget_idx=-1,\n",
    "\tfeature_names=['A1','A2','A3','A4','A5','A6','A7','A8','A9','A10','A11','A12','A13','A14','target'],\n",
    "\t# categorical_features=None,\n",
    "\t# features_to_use=None,\n",
    "\t# feature_transformations=None,\n",
    "\t# discretize=False,\n",
    "\t# balance=False,\n",
    "\t# fill_na='-1',\n",
    "\t# filter_fn=None,\n",
    "\tskip_first=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor import anchor_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    d.class_names,\n",
    "    d.feature_names,\n",
    "    d.train,\n",
    "    d.categorical_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x: tf.argmax(keras_model.predict(x)[0]).numpy().reshape(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in d.train:\n",
    "\ta == data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(data[i, :-1], predict_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_explanation(improved_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer.explain_instance(\n",
    "# \tdata_row,\n",
    "# \tclassifier_fn,\n",
    "# \tthreshold=0.95,\n",
    "# \tdelta=0.1,\n",
    "# \ttau=0.15,\n",
    "# \tbatch_size=100,\n",
    "# \tmax_anchor_size=None,\n",
    "# \tdesired_label=None,\n",
    "# \t**kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (main, Nov 24 2022, 19:45:47) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94856992579206d4c5c2d2f52c2407bb11394cd820c2ebd327ab285264c6684a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
